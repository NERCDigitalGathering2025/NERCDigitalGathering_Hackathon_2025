{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåç NERC Digital Gathering - Environmental Data Hackathon ‚Äî Soils & Land Cover Notebook\n",
        "\n",
        "Welcome to the NERC Digital Gathering hackathon!  \n",
        "This notebook contains the challenge briefs and starter code for you to explore weather, climate, and soil data available through CEDA and other sources. In the hackathon we invite you to use NERC data and to explore the CEDA archive. However, Cranfield hold the national soil map and so if your hack involves soil you can also use that dataset too.\n",
        "\n",
        "In the hackathon, we are offering a chance to explore and interact with a range of meteorological ands other data in CEDA - NERC's Centre for Environmental Data Analysis. The datasets we are looking at include ECMWF, HAD and MIDAS. These data are in different formats and structures so you can explore these differences as well.\n",
        "\n",
        "**MIDAS** (Met Office Integrated Data Archive System): This is a database of raw weather observations from land and marine surface stations, both in the UK and globally. It contains daily, hourly and sub-hourly measurements of various parameters like temperature, rainfall, sunshine, wind, cloud cover, and present weather codes. MIDAS data is station based timeseries data in CSV format.\n",
        "\n",
        "**ECMWF** (European Centre for Medium-Range Weather Forecasts): This organisation produces weather forecasts and climate reanalyses. ECMWF data includes estimates of atmospheric parameters like air temperature, pressure, and wind at different altitudes, as well as surface parameters like rainfall, soil moisture content, ocean-wave height, and sea-surface temperature, for the entire globe. They also have ocean reanalysis and analysis systems like OCEAN5. ECMWF has regional gridded data in NetCDF format.\n",
        "\n",
        "**HadUK-Grid** is a dataset of gridded climate variables for the UK derived from interpolated land surface observations. It focuses on climate variables like temperature, rainfall, sunshine, mean sea level pressure, wind speed, relative humidity, vapour pressure, days of snow lying, and days of ground frost, at daily, monthly, seasonal, and annual timescales. HADUK has regional gridded data in NetCDF format.\n",
        "\n",
        "**Soils and Land Cover** In addition to the meteorological notebooks, we are also running a fourth notebook that allows some comparison of soil types and land cover in the county of Bedfordshire. Our challenge is to undertake some spatial analysis to establish any patterns between the datasets. \n",
        "\n",
        "**This notebook sets some challenges using soils and land cover data for Bedfordshire.**\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Getting Started\n",
        "\n",
        "1. **Load libraries**  \n",
        "   The sorts of libraries you may need include `pandas`, `numpy`, `matplotlib`, `seaborn`, and `geopandas`.  \n",
        "   (Install with `pip install ...` if missing.)\n",
        "\n",
        "2. **Accessing external data**  \n",
        "   Example:\n",
        "   ```python\n",
        "   import pandas as pd\n",
        "   url = \"https://nercdigitalgathering2025.github.io/data/Bedfordshire_CORINE_Landcover_2018_100mGrid.csv\"\n",
        "   df = pd.read_csv(url)\n",
        "   print(df.head())\n",
        "   ```\n",
        "\n",
        "3. **Notebook structure**  \n",
        "   Each challenge is introduced in Markdown with background, tasks, and judging criteria.  \n",
        "   Under each challenge you'll find starter code cells to help you begin.  \n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Geographical focus\n",
        "In this hackathon, we will focus the hacking geographically. You can choose to look at the UK as a whole, or focus in on Bedfordshire where we are located. Geographical coordinates for these areas are as follows:\n",
        "\n",
        "* UK bounding box (roughly -10¬∞W to 3¬∞E, 49¬∞N to 61¬∞N)\n",
        "* Bedfordshire bounding box (roughly -0.89¬∞W to 0.23¬∞E, 51.95¬∞N to 52.49¬∞N)\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Useful links\n",
        "Here are a few useful web addressses for CEDA data:\n",
        "* CEDA Data home: https://data.ceda.ac.uk\n",
        "* CEDA Help Doc home: https://help.ceda.ac.uk\n",
        "* MIDAS User Guide: https://zenodo.org/records/7357335\n",
        "* ECMWF website - https://www.ecmwf.int\n",
        "* JASMIN Notebooks service help: https://help.jasmin.ac.uk/docs/interactive-computing/jasmin-notebooks-service/\n",
        "\n",
        "---\n",
        "\n",
        "# üìù Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 1 ‚Äî Load and Explore Land Cover Data\n",
        "\n",
        "### Background\n",
        "CORINE (Coordination of Information on the Environment) Land Cover data provides detailed information about land use and land cover across Europe. The Bedfordshire dataset contains 100m grid resolution data showing different land cover types such as agricultural areas, forests, urban areas, and water bodies.\n",
        "\n",
        "### Your Task\n",
        "Load the CORINE Land Cover dataset and perform initial exploration:\n",
        "- Load the CSV file from the provided URL\n",
        "- Examine the data structure, columns, and data types\n",
        "- Generate basic statistics about land cover distribution\n",
        "- Create visualisations showing land cover patterns\n",
        "\n",
        "**Success criteria:** successful data loading, clear understanding of data structure, informative statistics and visualisations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries for data processing, analysis, and visualisation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from urllib.request import urlretrieve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set plotting style for better visualisations\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define URLs for the datasets\n",
        "landcover_url = \"https://nercdigitalgathering2025.github.io/data/Bedfordshire_CORINE_Landcover_2018_100mGrid.csv\"\n",
        "soils_url = \"https://nercdigitalgathering2025.github.io/data/Bedfordshire_NATMAP_Soils_100mGrid.csv\"\n",
        "\n",
        "# Load the CORINE Land Cover dataset\n",
        "print(\"Loading CORINE Land Cover data...\")\n",
        "landcover_df = pd.read_csv(landcover_url)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(f\"Dataset shape: {landcover_df.shape}\")\n",
        "print(f\"Columns: {list(landcover_df.columns)}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "landcover_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine data types and basic statistics\n",
        "print(\"Data types:\")\n",
        "print(landcover_df.dtypes)\n",
        "print(\"\\nBasic statistics:\")\n",
        "print(landcover_df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(landcover_df.isnull().sum())\n",
        "\n",
        "# Display unique values in categorical columns (if any)\n",
        "print(\"\\nUnique values in each column:\")\n",
        "for col in landcover_df.columns:\n",
        "    unique_count = landcover_df[col].nunique()\n",
        "    print(f\"{col}: {unique_count} unique values\")\n",
        "    if unique_count <= 20:  # Show values if not too many\n",
        "        print(f\"  Values: {sorted(landcover_df[col].unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 2 ‚Äî Load and Explore Soils Data\n",
        "\n",
        "### Background\n",
        "The NATMAP Soils dataset provides detailed soil information for Bedfordshire at 100m grid resolution. This dataset contains various soil properties including soil type, texture, drainage characteristics, and other physical and chemical properties that are crucial for understanding agricultural potential, flood risk, and environmental processes.\n",
        "\n",
        "### Your Task\n",
        "Load the NATMAP Soils dataset and perform comprehensive analysis:\n",
        "- Load the CSV file from the provided URL\n",
        "- Examine the data structure and identify different soil properties\n",
        "- Generate statistics for numerical soil properties\n",
        "- Analyse categorical soil classifications\n",
        "- Create visualisations of soil distribution patterns\n",
        "\n",
        "**Success criteria:** successful data loading, thorough understanding of soil data structure, comprehensive statistical analysis, clear visualisations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the NATMAP Soils dataset\n",
        "print(\"Loading NATMAP Soils data...\")\n",
        "soils_df = pd.read_csv(soils_url)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(f\"Dataset shape: {soils_df.shape}\")\n",
        "print(f\"Columns: {list(soils_df.columns)}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "soils_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine data types and basic statistics\n",
        "print(\"Data types:\")\n",
        "print(soils_df.dtypes)\n",
        "print(\"\\nBasic statistics for numerical columns:\")\n",
        "print(soils_df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values:\")\n",
        "print(soils_df.isnull().sum())\n",
        "\n",
        "# Identify numerical vs categorical columns\n",
        "numerical_cols = soils_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = soils_df.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "print(f\"\\nNumerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
        "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
        "\n",
        "# Display unique values in categorical columns\n",
        "print(\"\\nUnique values in categorical columns:\")\n",
        "for col in categorical_cols:\n",
        "    unique_count = soils_df[col].nunique()\n",
        "    print(f\"{col}: {unique_count} unique values\")\n",
        "    if unique_count <= 15:  # Show values if not too many\n",
        "        print(f\"  Values: {sorted(soils_df[col].unique())}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 3 ‚Äî Statistical Analysis and Visualisation\n",
        "\n",
        "### Background\n",
        "Understanding the distribution and patterns in both land cover and soils data is essential for environmental analysis. Statistical analysis helps identify dominant land cover types, soil characteristics, and spatial patterns that can inform land management decisions.\n",
        "\n",
        "### Your Task\n",
        "Perform comprehensive statistical analysis and create informative visualisations:\n",
        "- Generate frequency distributions for land cover types\n",
        "- Analyse soil property distributions and correlations\n",
        "- Create spatial visualisations of both datasets\n",
        "- Identify patterns and anomalies in the data\n",
        "- Compare the spatial extent and coverage of both datasets\n",
        "\n",
        "**Success criteria:** comprehensive statistical analysis, clear and informative visualisations, identification of key patterns and relationships.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse land cover distribution\n",
        "print(\"=== LAND COVER ANALYSIS ===\")\n",
        "\n",
        "# Identify the main land cover column (assuming it's one of the columns)\n",
        "# This will need to be adjusted based on actual column names\n",
        "landcover_cols = [col for col in landcover_df.columns if 'land' in col.lower() or 'cover' in col.lower() or 'type' in col.lower()]\n",
        "print(f\"Potential land cover columns: {landcover_cols}\")\n",
        "\n",
        "# If we can identify a land cover type column, analyse it\n",
        "if landcover_cols:\n",
        "    main_col = landcover_cols[0]\n",
        "    print(f\"\\nAnalysing column: {main_col}\")\n",
        "    \n",
        "    # Frequency analysis\n",
        "    landcover_counts = landcover_df[main_col].value_counts()\n",
        "    print(\"\\nLand cover type frequencies:\")\n",
        "    print(landcover_counts)\n",
        "    \n",
        "    # Create visualisation\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    \n",
        "    # Bar plot of land cover types\n",
        "    plt.subplot(1, 2, 1)\n",
        "    landcover_counts.plot(kind='bar')\n",
        "    plt.title('Land Cover Type Distribution')\n",
        "    plt.xlabel('Land Cover Type')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Pie chart of land cover types\n",
        "    plt.subplot(1, 2, 2)\n",
        "    landcover_counts.plot(kind='pie', autopct='%1.1f%%')\n",
        "    plt.title('Land Cover Type Proportions')\n",
        "    plt.ylabel('')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Could not identify land cover column. Please examine the data structure above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyse soils data\n",
        "print(\"=== SOILS ANALYSIS ===\")\n",
        "\n",
        "# Analyse numerical soil properties\n",
        "if numerical_cols:\n",
        "    print(f\"\\nAnalysing {len(numerical_cols)} numerical soil properties:\")\n",
        "    \n",
        "    # Create correlation matrix for numerical properties\n",
        "    if len(numerical_cols) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        correlation_matrix = soils_df[numerical_cols].corr()\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
        "                   square=True, fmt='.2f')\n",
        "        plt.title('Correlation Matrix of Soil Properties')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    # Create distribution plots for key numerical properties\n",
        "    key_properties = numerical_cols[:4]  # Show first 4 numerical properties\n",
        "    if key_properties:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        axes = axes.ravel()\n",
        "        \n",
        "        for i, prop in enumerate(key_properties):\n",
        "            if i < len(axes):\n",
        "                soils_df[prop].hist(bins=30, ax=axes[i], alpha=0.7)\n",
        "                axes[i].set_title(f'Distribution of {prop}')\n",
        "                axes[i].set_xlabel(prop)\n",
        "                axes[i].set_ylabel('Frequency')\n",
        "        \n",
        "        # Hide unused subplots\n",
        "        for i in range(len(key_properties), len(axes)):\n",
        "            axes[i].set_visible(False)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Analyse categorical soil properties\n",
        "if categorical_cols:\n",
        "    print(f\"\\nAnalysing {len(categorical_cols)} categorical soil properties:\")\n",
        "    \n",
        "    # Show frequency distributions for categorical properties\n",
        "    for col in categorical_cols[:3]:  # Show first 3 categorical properties\n",
        "        print(f\"\\n{col} distribution:\")\n",
        "        value_counts = soils_df[col].value_counts()\n",
        "        print(value_counts.head(10))  # Show top 10 values\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 4 ‚Äî Spatial Analysis and Grid Comparison\n",
        "\n",
        "### Background\n",
        "Both datasets are provided at 100m grid resolution for Bedfordshire. Understanding the spatial relationship between land cover and soil properties is crucial for environmental analysis, agricultural planning, and ecosystem management.\n",
        "\n",
        "### Your Task\n",
        "Perform spatial analysis and intercomparison of the datasets:\n",
        "- Identify common grid coordinates between the datasets\n",
        "- Create spatial visualisations showing the distribution of both datasets\n",
        "- Analyse the relationship between land cover types and soil properties\n",
        "- Identify areas of overlap and potential data gaps\n",
        "- Create summary statistics for grid cell comparisons\n",
        "\n",
        "**Success criteria:** successful spatial analysis, clear understanding of dataset relationships, informative spatial visualisations, meaningful intercomparison results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spatial analysis and grid comparison\n",
        "print(\"=== SPATIAL ANALYSIS ===\")\n",
        "\n",
        "# Identify coordinate columns (assuming they contain 'x', 'y', 'lon', 'lat', 'east', 'north')\n",
        "coord_keywords = ['x', 'y', 'lon', 'lat', 'east', 'north', 'coord']\n",
        "landcover_coords = [col for col in landcover_df.columns if any(keyword in col.lower() for keyword in coord_keywords)]\n",
        "soils_coords = [col for col in soils_df.columns if any(keyword in col.lower() for keyword in coord_keywords)]\n",
        "\n",
        "print(f\"Land cover coordinate columns: {landcover_coords}\")\n",
        "print(f\"Soils coordinate columns: {soils_coords}\")\n",
        "\n",
        "# Check if we have coordinate information\n",
        "if landcover_coords and soils_coords:\n",
        "    print(\"\\nCoordinate information found in both datasets\")\n",
        "    \n",
        "    # Display coordinate ranges\n",
        "    print(\"\\nLand cover coordinate ranges:\")\n",
        "    for col in landcover_coords:\n",
        "        print(f\"{col}: {landcover_df[col].min():.2f} to {landcover_df[col].max():.2f}\")\n",
        "    \n",
        "    print(\"\\nSoils coordinate ranges:\")\n",
        "    for col in soils_coords:\n",
        "        print(f\"{col}: {soils_df[col].min():.2f} to {soils_df[col].max():.2f}\")\n",
        "    \n",
        "    # Create spatial scatter plots if we have 2D coordinates\n",
        "    if len(landcover_coords) >= 2 and len(soils_coords) >= 2:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "        \n",
        "        # Land cover spatial plot\n",
        "        axes[0].scatter(landcover_df[landcover_coords[0]], landcover_df[landcover_coords[1]], \n",
        "                       alpha=0.6, s=1, c='blue')\n",
        "        axes[0].set_xlabel(landcover_coords[0])\n",
        "        axes[0].set_ylabel(landcover_coords[1])\n",
        "        axes[0].set_title('Land Cover Data Spatial Distribution')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Soils spatial plot\n",
        "        axes[1].scatter(soils_df[soils_coords[0]], soils_df[soils_coords[1]], \n",
        "                       alpha=0.6, s=1, c='red')\n",
        "        axes[1].set_xlabel(soils_coords[0])\n",
        "        axes[1].set_ylabel(soils_coords[1])\n",
        "        axes[1].set_title('Soils Data Spatial Distribution')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"Coordinate information not clearly identified. Please examine the data structure above.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Challenge 5 ‚Äî Advanced Intercomparison Analysis\n",
        "\n",
        "### Background\n",
        "Understanding the relationships between land cover and soil properties is crucial for environmental management, agricultural planning, and ecosystem services assessment. Advanced analysis can reveal patterns that inform land use decisions and environmental policy.\n",
        "\n",
        "### Your Task\n",
        "Perform advanced intercomparison analysis between land cover and soils data:\n",
        "- Create cross-tabulation analysis between land cover types and soil properties\n",
        "- Identify correlations between land cover and soil characteristics\n",
        "- Perform statistical tests to identify significant relationships\n",
        "- Create comprehensive visualisations showing land cover-soil relationships\n",
        "- Generate summary reports of key findings\n",
        "\n",
        "**Success criteria:** thorough intercomparison analysis, identification of meaningful relationships, clear statistical interpretation, comprehensive visualisations, actionable insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced intercomparison analysis\n",
        "print(\"=== ADVANCED INTERCOMPARISON ANALYSIS ===\")\n",
        "\n",
        "# This analysis will depend on the actual structure of the data\n",
        "# We'll create a framework that can be adapted based on the column names\n",
        "\n",
        "# Identify key columns for analysis\n",
        "print(\"Available columns for analysis:\")\n",
        "print(f\"Land cover: {list(landcover_df.columns)}\")\n",
        "print(f\"Soils: {list(soils_df.columns)}\")\n",
        "\n",
        "# Create a merged dataset if we have common coordinates\n",
        "if landcover_coords and soils_coords:\n",
        "    print(\"\\nCreating merged dataset for intercomparison...\")\n",
        "    \n",
        "    # Create coordinate-based merge\n",
        "    landcover_df['coord_key'] = list(zip(landcover_df[landcover_coords[0]], landcover_df[landcover_coords[1]]))\n",
        "    soils_df['coord_key'] = list(zip(soils_df[soils_coords[0]], soils_df[soils_coords[1]]))\n",
        "    \n",
        "    # Merge datasets on coordinates\n",
        "    merged_df = pd.merge(landcover_df, soils_df, on='coord_key', how='inner', suffixes=('_lc', '_soil'))\n",
        "    \n",
        "    print(f\"Merged dataset shape: {merged_df.shape}\")\n",
        "    print(f\"Successfully merged {len(merged_df)} grid cells\")\n",
        "    \n",
        "    # Display merged dataset structure\n",
        "    print(\"\\nMerged dataset columns:\")\n",
        "    print(list(merged_df.columns))\n",
        "    \n",
        "    # Create correlation analysis between land cover and soil properties\n",
        "    if len(merged_df) > 10:  # Only if we have enough data\n",
        "        print(\"\\n=== CORRELATION ANALYSIS ===\")\n",
        "        \n",
        "        # Identify numerical columns for correlation\n",
        "        merged_numerical = merged_df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        \n",
        "        if len(merged_numerical) > 1:\n",
        "            # Create correlation matrix\n",
        "            plt.figure(figsize=(12, 10))\n",
        "            correlation_matrix = merged_df[merged_numerical].corr()\n",
        "            \n",
        "            # Create heatmap\n",
        "            mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "            sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', \n",
        "                       center=0, square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
        "            plt.title('Correlation Matrix: Land Cover vs Soil Properties')\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            # Identify strongest correlations\n",
        "            print(\"\\nStrongest correlations (|r| > 0.3):\")\n",
        "            for i in range(len(correlation_matrix.columns)):\n",
        "                for j in range(i+1, len(correlation_matrix.columns)):\n",
        "                    corr_val = correlation_matrix.iloc[i, j]\n",
        "                    if abs(corr_val) > 0.3:\n",
        "                        print(f\"{correlation_matrix.columns[i]} vs {correlation_matrix.columns[j]}: {corr_val:.3f}\")\n",
        "    \n",
        "    # Create summary statistics for merged data\n",
        "    print(\"\\n=== MERGED DATA SUMMARY ===\")\n",
        "    print(f\"Total merged grid cells: {len(merged_df):,}\")\n",
        "    print(f\"Coverage area: {len(merged_df) * 100 * 100 / 1_000_000:.2f} km¬≤\")\n",
        "    \n",
        "    # Data completeness\n",
        "    print(\"\\nData completeness in merged dataset:\")\n",
        "    completeness = (1 - merged_df.isnull().sum() / len(merged_df)) * 100\n",
        "    for col, comp in completeness.items():\n",
        "        if comp < 100:\n",
        "            print(f\"{col}: {comp:.1f}% complete\")\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot perform intercomparison analysis without coordinate overlap.\")\n",
        "    print(\"Please check the coordinate columns and ensure both datasets cover the same area.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
